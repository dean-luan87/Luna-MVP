#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Luna Badge è§†è§‰OCRå¼•æ“
é›†æˆ PaddleOCR + YOLOv8n å®ç°å¤šæ¨¡æ€è¯†åˆ«
"""

import logging
import cv2
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
import time

logger = logging.getLogger(__name__)

@dataclass
class OCRResult:
    """OCRè¯†åˆ«ç»“æœ"""
    text: str                    # è¯†åˆ«çš„æ–‡æœ¬
    confidence: float            # ç½®ä¿¡åº¦
    box: List[List[int]]         # æ–‡æœ¬æ¡†åæ ‡
    detected_class: str = None   # YOLOæ£€æµ‹åˆ°çš„ç±»åˆ«
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "text": self.text,
            "confidence": self.confidence,
            "box": self.box,
            "detected_class": self.detected_class
        }

class VisionOCREngine:
    """
    è§†è§‰OCRå¼•æ“
    ç»„åˆYOLOv8ç‰©ä½“æ£€æµ‹ + PaddleOCRæ–‡å­—è¯†åˆ«
    """
    
    def __init__(self, use_yolo: bool = True, use_ocr: bool = True):
        """
        åˆå§‹åŒ–è§†è§‰OCRå¼•æ“
        
        Args:
            use_yolo: æ˜¯å¦ä½¿ç”¨YOLOæ£€æµ‹
            use_ocr: æ˜¯å¦ä½¿ç”¨OCRè¯†åˆ«
        """
        self.use_yolo = use_yolo
        self.use_ocr = use_ocr
        self.yolo_model = None
        self.ocr_model = None
        
        logger.info(f"ğŸ¯ è§†è§‰OCRå¼•æ“åˆå§‹åŒ– (YOLO={use_yolo}, OCR={use_ocr})")
    
    def _init_yolo(self):
        """åˆå§‹åŒ–YOLOæ¨¡å‹"""
        if not self.use_yolo:
            return
        
        try:
            from ultralytics import YOLO
            
            logger.info("æ­£åœ¨åŠ è½½YOLOv8æ¨¡å‹...")
            self.yolo_model = YOLO('yolov8n.pt')  # nanoç‰ˆæœ¬ï¼Œè½»é‡çº§
            
            logger.info("âœ… YOLOv8æ¨¡å‹åŠ è½½æˆåŠŸ")
        except ImportError:
            logger.error("âŒ æœªå®‰è£…ultralyticsï¼Œè¯·è¿è¡Œ: pip install ultralytics")
        except Exception as e:
            logger.error(f"âŒ YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def _init_ocr(self):
        """åˆå§‹åŒ–PaddleOCRæ¨¡å‹"""
        if not self.use_ocr:
            return
        
        try:
            from paddleocr import PaddleOCR
            
            logger.info("æ­£åœ¨åŠ è½½PaddleOCRæ¨¡å‹...")
            # æ–°ç‰ˆæœ¬PaddleOCRçš„åˆå§‹åŒ–
            self.ocr_model = PaddleOCR(
                lang='ch'  # ä¸­æ–‡è¯†åˆ«
            )
            
            logger.info("âœ… PaddleOCRæ¨¡å‹åŠ è½½æˆåŠŸ")
        except ImportError:
            logger.error("âŒ æœªå®‰è£…PaddleOCRï¼Œè¯·è¿è¡Œ: pip install paddleocr paddlepaddle")
        except Exception as e:
            logger.error(f"âŒ PaddleOCRæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def load_models(self) -> bool:
        """
        åŠ è½½æ‰€æœ‰æ¨¡å‹
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸåŠ è½½
        """
        try:
            self._init_yolo()
            self._init_ocr()
            return True
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
    
    def detect_objects(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨YOLOæ£€æµ‹ç‰©ä½“
        
        Args:
            image: è¾“å…¥å›¾åƒ
            
        Returns:
            List[Dict]: æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        if not self.use_yolo or self.yolo_model is None:
            return []
        
        try:
            results = self.yolo_model(image, verbose=False)
            
            detections = []
            for result in results:
                boxes = result.boxes
                for box in boxes:
                    class_id = int(box.cls)
                    confidence = float(box.conf)
                    class_name = result.names[class_id]
                    
                    # è·å–è¾¹ç•Œæ¡†åæ ‡
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    
                    detections.append({
                        "class": class_name,
                        "confidence": confidence,
                        "box": [int(x1), int(y1), int(x2), int(y2)],
                        "center": (int((x1 + x2) / 2), int((y1 + y2) / 2))
                    })
            
            return detections
        except Exception as e:
            logger.error(f"âŒ YOLOæ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def recognize_text(self, image: np.ndarray, roi: List[int] = None) -> List[OCRResult]:
        """
        ä½¿ç”¨OCRè¯†åˆ«æ–‡å­—
        
        Args:
            image: è¾“å…¥å›¾åƒ
            roi: æ„Ÿå…´è¶£åŒºåŸŸ [x1, y1, x2, y2]ï¼Œå¦‚æœä¸ºNoneåˆ™è¯†åˆ«æ•´ä¸ªå›¾åƒ
            
        Returns:
            List[OCRResult]: è¯†åˆ«ç»“æœåˆ—è¡¨
        """
        if not self.use_ocr or self.ocr_model is None:
            return []
        
        try:
            # å¦‚æœæŒ‡å®šäº†ROIï¼Œè£å‰ªå›¾åƒ
            if roi is not None:
                x1, y1, x2, y2 = roi
                image = image[y1:y2, x1:x2]
            
            # OCRè¯†åˆ«ï¼ˆæ–°ç‰ˆæœ¬API - ä½¿ç”¨.predict()æ–¹æ³•ï¼‰
            results = self.ocr_model.predict(image)
            
            ocr_results = []
            if results and len(results) > 0:
                result_obj = results[0]
                # æå–æ–‡å­—å’Œåˆ†æ•°
                rec_texts = result_obj.get('rec_texts', [])
                rec_scores = result_obj.get('rec_scores', [])
                rec_polys = result_obj.get('rec_polys', [])
                
                for i, text in enumerate(rec_texts):
                    if i < len(rec_scores) and i < len(rec_polys):
                        score = rec_scores[i]
                        box = rec_polys[i].tolist() if hasattr(rec_polys[i], 'tolist') else rec_polys[i]
                        
                        ocr_results.append(OCRResult(
                            text=text,
                            confidence=score,
                            box=box
                        ))
            
            return ocr_results
        except Exception as e:
            logger.error(f"âŒ OCRè¯†åˆ«å¤±è´¥: {e}")
            return []
    
    def detect_and_recognize(self, image: np.ndarray) -> Dict[str, Any]:
        """
        æ£€æµ‹ç‰©ä½“å¹¶è¯†åˆ«æ–‡å­—ï¼ˆç»„åˆYOLO + OCRï¼‰
        
        Args:
            image: è¾“å…¥å›¾åƒ
            
        Returns:
            Dict: åŒ…å«æ£€æµ‹å’Œè¯†åˆ«ç»“æœçš„å­—å…¸
        """
        start_time = time.time()
        
        # 1. YOLOç‰©ä½“æ£€æµ‹
        detections = self.detect_objects(image) if self.use_yolo else []
        
        # 2. OCRæ–‡å­—è¯†åˆ«
        ocr_results = self.recognize_text(image) if self.use_ocr else []
        
        # 3. ç»„åˆç»“æœï¼ˆå°†OCRç»“æœä¸æœ€è¿‘çš„ç‰©ä½“å…³è”ï¼‰
        combined_results = self._combine_results(detections, ocr_results)
        
        processing_time = time.time() - start_time
        
        return {
            "detections": detections,
            "ocr_results": [r.to_dict() for r in ocr_results],
            "combined": combined_results,
            "processing_time": processing_time
        }
    
    def _combine_results(self, detections: List[Dict], ocr_results: List[OCRResult]) -> List[Dict]:
        """
        ç»„åˆYOLOæ£€æµ‹ç»“æœå’ŒOCRè¯†åˆ«ç»“æœ
        
        Args:
            detections: YOLOæ£€æµ‹ç»“æœ
            ocr_results: OCRè¯†åˆ«ç»“æœ
            
        Returns:
            List[Dict]: ç»„åˆåçš„ç»“æœ
        """
        combined = []
        
        for ocr in ocr_results:
            # æ‰¾åˆ°æœ€è¿‘çš„ç‰©ä½“
            nearest_detection = self._find_nearest_detection(ocr.box, detections)
            
            combined.append({
                "text": ocr.text,
                "confidence": ocr.confidence,
                "box": ocr.box,
                "detected_class": nearest_detection["class"] if nearest_detection else None,
                "object_confidence": nearest_detection["confidence"] if nearest_detection else None
            })
        
        return combined
    
    def _find_nearest_detection(self, ocr_box: List[List[int]], detections: List[Dict]) -> Optional[Dict]:
        """
        æ‰¾åˆ°ä¸OCRæ¡†æœ€è¿‘çš„ç‰©ä½“æ£€æµ‹ç»“æœ
        
        Args:
            ocr_box: OCRè¾¹ç•Œæ¡†
            detections: ç‰©ä½“æ£€æµ‹ç»“æœ
            
        Returns:
            Optional[Dict]: æœ€è¿‘çš„ç‰©ä½“æ£€æµ‹ç»“æœ
        """
        if not detections:
            return None
        
        # è®¡ç®—OCRæ¡†çš„ä¸­å¿ƒç‚¹
        ocr_center = np.array([
            (ocr_box[0][0] + ocr_box[2][0]) / 2,
            (ocr_box[0][1] + ocr_box[2][1]) / 2
        ])
        
        min_distance = float('inf')
        nearest = None
        
        for detection in detections:
            det_center = np.array(detection["center"])
            distance = np.linalg.norm(ocr_center - det_center)
            
            if distance < min_distance:
                min_distance = distance
                nearest = detection
        
        return nearest if min_distance < 100 else None  # è·ç¦»é˜ˆå€¼100åƒç´ 
    
    def recognize_roi(self, image: np.ndarray, roi: List[int]) -> List[OCRResult]:
        """
        åœ¨æŒ‡å®šåŒºåŸŸè¯†åˆ«æ–‡å­—
        
        Args:
            image: è¾“å…¥å›¾åƒ
            roi: æ„Ÿå…´è¶£åŒºåŸŸ [x1, y1, x2, y2]
            
        Returns:
            List[OCRResult]: è¯†åˆ«ç»“æœ
        """
        return self.recognize_text(image, roi)


# å…¨å±€å¼•æ“å®ä¾‹
_vision_ocr_engine: Optional[VisionOCREngine] = None

def get_vision_ocr_engine(use_yolo: bool = True, use_ocr: bool = True) -> VisionOCREngine:
    """
    è·å–å…¨å±€è§†è§‰OCRå¼•æ“å®ä¾‹
    
    Args:
        use_yolo: æ˜¯å¦ä½¿ç”¨YOLO
        use_ocr: æ˜¯å¦ä½¿ç”¨OCR
        
    Returns:
        VisionOCREngine: å¼•æ“å®ä¾‹
    """
    global _vision_ocr_engine
    
    if _vision_ocr_engine is None:
        _vision_ocr_engine = VisionOCREngine(use_yolo, use_ocr)
        _vision_ocr_engine.load_models()
    
    return _vision_ocr_engine


if __name__ == "__main__":
    # æµ‹è¯•è§†è§‰OCRå¼•æ“
    import logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
    
    print("=" * 60)
    print("ğŸ¯ è§†è§‰OCRå¼•æ“æµ‹è¯•")
    print("=" * 60)
    
    engine = VisionOCREngine()
    
    # åŠ è½½æ¨¡å‹
    if engine.load_models():
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        print(f"   YOLO: {engine.yolo_model is not None}")
        print(f"   OCR: {engine.ocr_model is not None}")
    else:
        print("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
    
    print("\n" + "=" * 60)
