#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Luna è®°å¿†ç¼“å­˜ç®¡ç†å™¨
æ”¯æŒç”¨æˆ·ç«¯ç¼“å­˜ç®¡ç†å’Œt+1ä¸Šä¼ æœºåˆ¶
"""

import json
import logging
import os
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any
import hashlib

logger = logging.getLogger(__name__)


class MemoryCacheManager:
    """è®°å¿†ç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir: str = "data/cache"):
        """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨"""
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        # ç¼“å­˜æ–‡ä»¶
        self.maps_cache_file = self.cache_dir / "maps_cache.json"
        self.scenes_cache_file = self.cache_dir / "scenes_cache.json"
        self.user_behavior_cache_file = self.cache_dir / "user_behavior_cache.json"
        self.upload_queue_file = self.cache_dir / "upload_queue.json"
        self.last_upload_file = self.cache_dir / "last_upload.json"
        
        # åˆå§‹åŒ–ç¼“å­˜
        self._init_cache()
        
        logger.info("ğŸ’¾ è®°å¿†ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _init_cache(self):
        """åˆå§‹åŒ–ç¼“å­˜æ–‡ä»¶"""
        if not self.maps_cache_file.exists():
            self._save_cache(self.maps_cache_file, {"maps": [], "last_update": None})
        
        if not self.scenes_cache_file.exists():
            self._save_cache(self.scenes_cache_file, {"scenes": [], "last_update": None})
        
        if not self.user_behavior_cache_file.exists():
            self._save_cache(self.user_behavior_cache_file, {
                "behaviors": [],
                "preferences": {},
                "habits": {},
                "last_update": None
            })
        
        if not self.upload_queue_file.exists():
            self._save_cache(self.upload_queue_file, {"queue": [], "last_check": None})
        
        if not self.last_upload_file.exists():
            self._save_cache(self.last_upload_file, {
                "last_upload_time": None,
                "upload_count": 0
            })
    
    def cache_map(self, map_data: Dict, metadata: Optional[Dict] = None) -> bool:
        """ç¼“å­˜åœ°å›¾æ•°æ®
        
        Args:
            map_data: åœ°å›¾æ•°æ®
            metadata: å…ƒæ•°æ®
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            cache_data = self._load_cache(self.maps_cache_file)
            
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
            map_id = map_data.get("map_id") or map_data.get("path_id")
            existing_maps = [m for m in cache_data.get("maps", []) if m.get("map_id") == map_id]
            
            if existing_maps:
                # æ›´æ–°ç°æœ‰è®°å½•
                index = cache_data["maps"].index(existing_maps[0])
                cache_data["maps"][index] = {
                    "map_id": map_id,
                    "map_data": map_data,
                    "metadata": metadata,
                    "cached_at": datetime.now().isoformat(),
                    "uploaded": False
                }
            else:
                # æ·»åŠ æ–°è®°å½•
                cache_data["maps"].append({
                    "map_id": map_id,
                    "map_data": map_data,
                    "metadata": metadata,
                    "cached_at": datetime.now().isoformat(),
                    "uploaded": False
                })
            
            cache_data["last_update"] = datetime.now().isoformat()
            self._save_cache(self.maps_cache_file, cache_data)
            
            # æ·»åŠ åˆ°ä¸Šä¼ é˜Ÿåˆ—
            self._add_to_upload_queue("map", map_id)
            
            logger.info(f"âœ… åœ°å›¾å·²ç¼“å­˜ï¼š{map_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜åœ°å›¾å¤±è´¥ï¼š{e}")
            return False
    
    def cache_scene(self, scene_data: Dict) -> bool:
        """ç¼“å­˜åœºæ™¯è®°å¿†
        
        Args:
            scene_data: åœºæ™¯æ•°æ®
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            cache_data = self._load_cache(self.scenes_cache_file)
            
            scene_id = scene_data.get("scene_id") or f"scene_{int(time.time())}"
            
            cache_data["scenes"].append({
                "scene_id": scene_id,
                "scene_data": scene_data,
                "cached_at": datetime.now().isoformat(),
                "uploaded": False
            })
            
            cache_data["last_update"] = datetime.now().isoformat()
            self._save_cache(self.scenes_cache_file, cache_data)
            
            # æ·»åŠ åˆ°ä¸Šä¼ é˜Ÿåˆ—
            self._add_to_upload_queue("scene", scene_id)
            
            logger.info(f"âœ… åœºæ™¯å·²ç¼“å­˜ï¼š{scene_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜åœºæ™¯å¤±è´¥ï¼š{e}")
            return False
    
    def cache_user_behavior(self, behavior_type: str, behavior_data: Dict) -> bool:
        """ç¼“å­˜ç”¨æˆ·è¡Œä¸ºæ•°æ®
        
        Args:
            behavior_type: è¡Œä¸ºç±»å‹ï¼ˆnavigation, voice, preferenceç­‰ï¼‰
            behavior_data: è¡Œä¸ºæ•°æ®
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            cache_data = self._load_cache(self.user_behavior_cache_file)
            
            behavior_id = f"{behavior_type}_{int(time.time())}"
            
            cache_data["behaviors"].append({
                "behavior_id": behavior_id,
                "behavior_type": behavior_type,
                "behavior_data": behavior_data,
                "timestamp": datetime.now().isoformat(),
                "cached_at": datetime.now().isoformat(),
                "uploaded": False
            })
            
            # å¦‚æœè¶…è¿‡1000æ¡è¡Œä¸ºè®°å½•ï¼Œåªä¿ç•™æœ€è¿‘1000æ¡
            if len(cache_data["behaviors"]) > 1000:
                cache_data["behaviors"] = cache_data["behaviors"][-1000:]
            
            cache_data["last_update"] = datetime.now().isoformat()
            self._save_cache(self.user_behavior_cache_file, cache_data)
            
            # æ·»åŠ åˆ°ä¸Šä¼ é˜Ÿåˆ—
            self._add_to_upload_queue("behavior", behavior_id)
            
            logger.debug(f"âœ… ç”¨æˆ·è¡Œä¸ºå·²ç¼“å­˜ï¼š{behavior_type}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ç¼“å­˜ç”¨æˆ·è¡Œä¸ºå¤±è´¥ï¼š{e}")
            return False
    
    def update_user_preferences(self, preferences: Dict) -> bool:
        """æ›´æ–°ç”¨æˆ·åå¥½è®¾ç½®
        
        Args:
            preferences: åå¥½è®¾ç½®
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            cache_data = self._load_cache(self.user_behavior_cache_file)
            
            # åˆå¹¶åå¥½è®¾ç½®
            if "preferences" not in cache_data:
                cache_data["preferences"] = {}
            
            cache_data["preferences"].update(preferences)
            cache_data["last_update"] = datetime.now().isoformat()
            
            self._save_cache(self.user_behavior_cache_file, cache_data)
            
            # æ ‡è®°åå¥½éœ€è¦ä¸Šä¼ 
            self._add_to_upload_queue("preference", "all")
            
            logger.info("âœ… ç”¨æˆ·åå¥½å·²æ›´æ–°")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ç”¨æˆ·åå¥½å¤±è´¥ï¼š{e}")
            return False
    
    def record_navigation_event(self, event_type: str, data: Dict) -> bool:
        """è®°å½•å¯¼èˆªäº‹ä»¶
        
        Args:
            event_type: äº‹ä»¶ç±»å‹
            data: äº‹ä»¶æ•°æ®
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        event_data = {
            "event_type": event_type,
            "data": data,
            "timestamp": datetime.now().isoformat()
        }
        
        return self.cache_user_behavior("navigation", event_data)
    
    def record_voice_interaction(self, interaction_type: str, data: Dict) -> bool:
        """è®°å½•è¯­éŸ³äº¤äº’
        
        Args:
            interaction_type: äº¤äº’ç±»å‹
            data: äº¤äº’æ•°æ®
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        interaction_data = {
            "interaction_type": interaction_type,
            "data": data,
            "timestamp": datetime.now().isoformat()
        }
        
        return self.cache_user_behavior("voice", interaction_data)
    
    def get_cache_stats(self) -> Dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        maps_cache = self._load_cache(self.maps_cache_file)
        scenes_cache = self._load_cache(self.scenes_cache_file)
        behavior_cache = self._load_cache(self.user_behavior_cache_file)
        upload_queue = self._load_cache(self.upload_queue_file)
        last_upload = self._load_cache(self.last_upload_file)
        
        stats = {
            "total_maps": len(maps_cache.get("maps", [])),
            "unuploaded_maps": len([m for m in maps_cache.get("maps", []) if not m.get("uploaded")]),
            "total_scenes": len(scenes_cache.get("scenes", [])),
            "unuploaded_scenes": len([s for s in scenes_cache.get("scenes", []) if not s.get("uploaded")]),
            "total_behaviors": len(behavior_cache.get("behaviors", [])),
            "unuploaded_behaviors": len([b for b in behavior_cache.get("behaviors", []) if not b.get("uploaded")]),
            "upload_queue_size": len(upload_queue.get("queue", [])),
            "last_upload_time": last_upload.get("last_upload_time"),
            "upload_count": last_upload.get("upload_count", 0),
            "cache_size_kb": self._calculate_cache_size()
        }
        
        return stats
    
    def _calculate_cache_size(self) -> float:
        """è®¡ç®—ç¼“å­˜å¤§å°ï¼ˆKBï¼‰"""
        total_size = 0
        
        for file_path in [
            self.maps_cache_file,
            self.scenes_cache_file,
            self.user_behavior_cache_file,
            self.upload_queue_file
        ]:
            if file_path.exists():
                total_size += file_path.stat().st_size
        
        return round(total_size / 1024, 2)
    
    def _add_to_upload_queue(self, data_type: str, data_id: str):
        """æ·»åŠ åˆ°ä¸Šä¼ é˜Ÿåˆ—
        
        Args:
            data_type: æ•°æ®ç±»å‹
            data_id: æ•°æ®ID
        """
        queue_data = self._load_cache(self.upload_queue_file)
        
        # æ£€æŸ¥æ˜¯å¦å·²åœ¨é˜Ÿåˆ—ä¸­
        existing = [q for q in queue_data.get("queue", []) 
                   if q.get("data_type") == data_type and q.get("data_id") == data_id]
        
        if not existing:
            queue_data["queue"].append({
                "data_type": data_type,
                "data_id": data_id,
                "added_at": datetime.now().isoformat(),
                "retry_count": 0
            })
            
            queue_data["last_check"] = datetime.now().isoformat()
            self._save_cache(self.upload_queue_file, queue_data)
    
    def get_upload_queue(self) -> List[Dict]:
        """è·å–ä¸Šä¼ é˜Ÿåˆ—
        
        Returns:
            ä¸Šä¼ é˜Ÿåˆ—åˆ—è¡¨
        """
        queue_data = self._load_cache(self.upload_queue_file)
        return queue_data.get("queue", [])
    
    def clear_cache(self, confirm: bool = False) -> bool:
        """æ¸…ç©ºç¼“å­˜ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
        
        Args:
            confirm: ç¡®è®¤æ ‡å¿—
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        if not confirm:
            logger.warning("âš ï¸ è¯·ç¡®è®¤æ˜¯å¦è¦æ¸…ç©ºç¼“å­˜")
            return False
        
        try:
            self._init_cache()
            logger.info("âœ… ç¼“å­˜å·²æ¸…ç©º")
            return True
        except Exception as e:
            logger.error(f"âŒ æ¸…ç©ºç¼“å­˜å¤±è´¥ï¼š{e}")
            return False
    
    def _load_cache(self, file_path: Path) -> Dict:
        """åŠ è½½ç¼“å­˜æ•°æ®"""
        if not file_path.exists():
            return {}
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ç¼“å­˜å¤±è´¥ {file_path}: {e}")
            return {}
    
    def _save_cache(self, file_path: Path, data: Dict):
        """ä¿å­˜ç¼“å­˜æ•°æ®"""
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç¼“å­˜å¤±è´¥ {file_path}: {e}")
    
    def export_cache_for_upload(self) -> Dict:
        """å¯¼å‡ºéœ€è¦ä¸Šä¼ çš„ç¼“å­˜æ•°æ®
        
        Returns:
            å‡†å¤‡ä¸Šä¼ çš„æ•°æ®åŒ…
        """
        maps_cache = self._load_cache(self.maps_cache_file)
        scenes_cache = self._load_cache(self.scenes_cache_file)
        behavior_cache = self._load_cache(self.user_behavior_cache_file)
        
        # ç­›é€‰æœªä¸Šä¼ çš„æ•°æ®
        unuploaded_maps = [m for m in maps_cache.get("maps", []) if not m.get("uploaded")]
        unuploaded_scenes = [s for s in scenes_cache.get("scenes", []) if not s.get("uploaded")]
        unuploaded_behaviors = [b for b in behavior_cache.get("behaviors", []) if not b.get("uploaded")]
        
        upload_package = {
            "timestamp": datetime.now().isoformat(),
            "maps": [m["map_data"] for m in unuploaded_maps],
            "scenes": [s["scene_data"] for s in unuploaded_scenes],
            "behaviors": [b["behavior_data"] for b in unuploaded_behaviors],
            "preferences": behavior_cache.get("preferences", {}),
            "metadata": {
                "maps_count": len(unuploaded_maps),
                "scenes_count": len(unuploaded_scenes),
                "behaviors_count": len(unuploaded_behaviors)
            }
        }
        
        return upload_package
    
    def mark_as_uploaded(self, data_type: str, data_id: str):
        """æ ‡è®°æ•°æ®å·²ä¸Šä¼ 
        
        Args:
            data_type: æ•°æ®ç±»å‹
            data_id: æ•°æ®ID
        """
        if data_type == "map":
            cache_file = self.maps_cache_file
        elif data_type == "scene":
            cache_file = self.scenes_cache_file
        elif data_type == "behavior":
            cache_file = self.user_behavior_cache_file
        else:
            return
        
        cache_data = self._load_cache(cache_file)
        
        # æ›´æ–°ä¸Šä¼ çŠ¶æ€
        for item in cache_data.get("maps" if data_type == "map" else "scenes" if data_type == "scene" else "behaviors", []):
            if item.get("map_id" if data_type == "map" else "scene_id" if data_type == "scene" else "behavior_id") == data_id:
                item["uploaded"] = True
                item["uploaded_at"] = datetime.now().isoformat()
                break
        
        self._save_cache(cache_file, cache_data)
        
        # ä»ä¸Šä¼ é˜Ÿåˆ—ä¸­ç§»é™¤
        queue_data = self._load_cache(self.upload_queue_file)
        queue_data["queue"] = [q for q in queue_data.get("queue", []) 
                              if not (q.get("data_type") == data_type and q.get("data_id") == data_id)]
        self._save_cache(self.upload_queue_file, queue_data)


# æµ‹è¯•å‡½æ•°
if __name__ == "__main__":
    import logging
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
    cache_manager = MemoryCacheManager()
    
    # æµ‹è¯•åœ°å›¾ç¼“å­˜
    print("=" * 60)
    print("ğŸ—ºï¸ æµ‹è¯•åœ°å›¾ç¼“å­˜")
    print("=" * 60)
    test_map = {
        "map_id": "test_map_001",
        "path_name": "æµ‹è¯•è·¯å¾„",
        "nodes": []
    }
    cache_manager.cache_map(test_map)
    
    # æµ‹è¯•åœºæ™¯ç¼“å­˜
    print("\nğŸï¸ æµ‹è¯•åœºæ™¯ç¼“å­˜")
    print("=" * 60)
    test_scene = {
        "scene_id": "scene_001",
        "location": "è™¹å£åŒ»é™¢",
        "caption": "åŒ»é™¢å…¥å£"
    }
    cache_manager.cache_scene(test_scene)
    
    # æµ‹è¯•ç”¨æˆ·è¡Œä¸ºç¼“å­˜
    print("\nğŸ‘¤ æµ‹è¯•ç”¨æˆ·è¡Œä¸ºç¼“å­˜")
    print("=" * 60)
    cache_manager.record_navigation_event("start_navigation", {
        "destination": "è™¹å£åŒ»é™¢",
        "route_type": "walking"
    })
    
    cache_manager.record_voice_interaction("voice_command", {
        "command": "å¯¼èˆªåˆ°è™¹å£åŒ»é™¢",
        "result": "success"
    })
    
    # æµ‹è¯•ç”¨æˆ·åå¥½
    print("\nâš™ï¸ æµ‹è¯•ç”¨æˆ·åå¥½")
    print("=" * 60)
    cache_manager.update_user_preferences({
        "voice_speed": "normal",
        "prefer_walk": True
    })
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print("\nğŸ“Š ç¼“å­˜ç»Ÿè®¡")
    print("=" * 60)
    stats = cache_manager.get_cache_stats()
    print(json.dumps(stats, indent=2, ensure_ascii=False))
    
    # å¯¼å‡ºä¸Šä¼ æ•°æ®åŒ…
    print("\nğŸ“¦ å¯¼å‡ºä¸Šä¼ æ•°æ®åŒ…")
    print("=" * 60)
    upload_package = cache_manager.export_cache_for_upload()
    print(f"æ•°æ®åŒ…å¤§å°ï¼š{json.dumps(upload_package).__len__()} å­—èŠ‚")
    print(f"åŒ…å« {upload_package['metadata']['maps_count']} ä¸ªåœ°å›¾")
    print(f"åŒ…å« {upload_package['metadata']['scenes_count']} ä¸ªåœºæ™¯")
    print(f"åŒ…å« {upload_package['metadata']['behaviors_count']} ä¸ªè¡Œä¸ºè®°å½•")

