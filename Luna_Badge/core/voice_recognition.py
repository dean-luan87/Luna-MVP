#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Luna Badge ç¦»çº¿è¯­éŸ³è¯†åˆ«æ¨¡å—
æ¥å…¥æœ¬åœ°è¯­éŸ³è¯†åˆ«æ¨¡å‹ï¼Œå®ç°åŸºç¡€å‘½ä»¤è¯†åˆ«
"""

import logging
import numpy as np
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import time

logger = logging.getLogger(__name__)

class VoiceIntent(Enum):
    """è¯­éŸ³æ„å›¾"""
    FORWARD = "forward"              # å‘å‰
    BACKWARD = "backward"            # å‘å
    STOP = "stop"                   # åœæ­¢
    DANGER = "danger"               # å±é™©
    EDGE_SIDE = "edge_side"         # é è¾¹
    SLOW_DOWN = "slow_down"         # å‡é€Ÿ
    HELP = "help"                   # æ±‚åŠ©
    UNKNOWN = "unknown"             # æœªçŸ¥

@dataclass
class VoiceCommand:
    """è¯­éŸ³å‘½ä»¤"""
    intent: VoiceIntent              # æ„å›¾
    keywords: List[str]              # è¯†åˆ«åˆ°çš„å…³é”®è¯
    confidence: float                # ç½®ä¿¡åº¦
    raw_text: str                   # åŸå§‹æ–‡æœ¬
    timestamp: float                # æ—¶é—´æˆ³
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "intent": self.intent.value,
            "keywords": self.keywords,
            "confidence": self.confidence,
            "raw_text": self.raw_text,
            "timestamp": self.timestamp
        }

class VoiceRecognitionEngine:
    """ç¦»çº¿è¯­éŸ³è¯†åˆ«å¼•æ“"""
    
    def __init__(self):
        """åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å¼•æ“"""
        self.logger = logging.getLogger(__name__)
        
        # å…³é”®è¯æ˜ å°„
        self.keyword_mapping = {
            VoiceIntent.FORWARD: [
                "å‘å‰", "å‰è¿›", "ç»§ç»­", "ç›´èµ°",
                "forward", "go ahead", "continue"
            ],
            VoiceIntent.BACKWARD: [
                "å‘å", "åé€€", "å¾€å›èµ°",
                "backward", "go back"
            ],
            VoiceIntent.STOP: [
                "åœæ­¢", "åœä¸‹", "æš‚åœ",
                "stop", "halt"
            ],
            VoiceIntent.DANGER: [
                "å±é™©", "æ³¨æ„", "å°å¿ƒ",
                "danger", "caution", "warning"
            ],
            VoiceIntent.EDGE_SIDE: [
                "é è¾¹", "é å³è¾¹", "é å·¦è¾¹",
                "edge", "side"
            ],
            VoiceIntent.SLOW_DOWN: [
                "å‡é€Ÿ", "æ…¢ç‚¹", "æ…¢ä¸‹æ¥",
                "slow down", "slow"
            ],
            VoiceIntent.HELP: [
                "å¸®åŠ©", "æ±‚åŠ©", "æ•‘å‘½",
                "help", "assist", "rescue"
            ]
        }
        
        # é¢„ç•™çš„çœŸå®å¼•æ“æ¥å£
        self.recognition_engine = None  # Voskæˆ–PicoVoiceå¼•æ“
        
        self.logger.info("ğŸ¤ ç¦»çº¿è¯­éŸ³è¯†åˆ«å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def recognize(self, audio_data: bytes = None, text: str = None) -> VoiceCommand:
        """
        è¯†åˆ«è¯­éŸ³å‘½ä»¤
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            text: æ–‡æœ¬ï¼ˆç”¨äºæ¨¡æ‹Ÿï¼‰
            
        Returns:
            VoiceCommand: è¯­éŸ³å‘½ä»¤
        """
        # å¦‚æœæœ‰çœŸå®å¼•æ“ï¼Œä½¿ç”¨çœŸå®å¼•æ“
        if self.recognition_engine and audio_data:
            recognized_text = self._recognize_with_engine(audio_data)
        else:
            # æ¨¡æ‹Ÿè¯†åˆ«
            recognized_text = text or self._simulate_recognition()
        
        # è§£ææ„å›¾
        intent, keywords, confidence = self._parse_intent(recognized_text)
        
        command = VoiceCommand(
            intent=intent,
            keywords=keywords,
            confidence=confidence,
            raw_text=recognized_text,
            timestamp=time.time()
        )
        
        self.logger.info(f"ğŸ¤ è¯†åˆ«ç»“æœ: {intent.value}, "
                        f"å…³é”®è¯={keywords}, ç½®ä¿¡åº¦={confidence:.2f}")
        
        return command
    
    def _recognize_with_engine(self, audio_data: bytes) -> str:
        """
        ä½¿ç”¨çœŸå®å¼•æ“è¯†åˆ«ï¼ˆé¢„ç•™æ¥å£ï¼‰
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®
            
        Returns:
            str: è¯†åˆ«åˆ°çš„æ–‡æœ¬
        """
        # TODO: é›†æˆVoskæˆ–PicoVoice
        # if self.recognition_engine is None:
        #     self.recognition_engine = init_vosk_engine()
        # 
        # result = self.recognition_engine.recognize(audio_data)
        # return result.get('text', '')
        
        return ""
    
    def _simulate_recognition(self) -> str:
        """æ¨¡æ‹Ÿè¯†åˆ«ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        # è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œç”±å¤–éƒ¨ä¼ å…¥text
        return ""
    
    def _parse_intent(self, text: str) -> Tuple[VoiceIntent, List[str], float]:
        """
        è§£æè¯­éŸ³æ„å›¾
        
        Args:
            text: è¯†åˆ«çš„æ–‡æœ¬
            
        Returns:
            Tuple[VoiceIntent, List[str], float]: (æ„å›¾, å…³é”®è¯åˆ—è¡¨, ç½®ä¿¡åº¦)
        """
        text_lower = text.lower()
        
        # æœç´¢åŒ¹é…çš„å…³é”®è¯
        matched_intents = []
        matched_keywords = []
        
        for intent, keywords in self.keyword_mapping.items():
            for keyword in keywords:
                if keyword.lower() in text_lower:
                    matched_intents.append(intent)
                    matched_keywords.append(keyword)
                    break
        
        if not matched_intents:
            return VoiceIntent.UNKNOWN, [], 0.0
        
        # é€‰æ‹©æœ€åŒ¹é…çš„æ„å›¾ï¼ˆå¦‚æœå¤šä¸ªåŒ¹é…ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªï¼‰
        intent = matched_intents[0]
        keywords = [k for k in matched_keywords if k]
        confidence = 0.9 if len(matched_keywords) > 0 else 0.5
        
        return intent, keywords, confidence


# å…¨å±€è¯†åˆ«å¼•æ“å®ä¾‹
global_voice_recognition = VoiceRecognitionEngine()

def recognize_voice(audio_data: bytes = None, text: str = None) -> VoiceCommand:
    """è¯†åˆ«è¯­éŸ³çš„ä¾¿æ·å‡½æ•°"""
    return global_voice_recognition.recognize(audio_data, text)


if __name__ == "__main__":
    # æµ‹è¯•è¯­éŸ³è¯†åˆ«
    import logging
    logging.basicConfig(level=logging.INFO)
    
    engine = VoiceRecognitionEngine()
    
    print("=" * 60)
    print("ğŸ¤ ç¦»çº¿è¯­éŸ³è¯†åˆ«æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•ä¸åŒçš„å‘½ä»¤
    test_cases = [
        ("å‘å‰èµ°", VoiceIntent.FORWARD),
        ("åœæ­¢", VoiceIntent.STOP),
        ("å±é™©", VoiceIntent.DANGER),
        ("é è¾¹", VoiceIntent.EDGE_SIDE),
        ("å‡é€Ÿ", VoiceIntent.SLOW_DOWN),
        ("å¸®åŠ©", VoiceIntent.HELP),
    ]
    
    for text, expected_intent in test_cases:
        result = engine.recognize(text=text)
        status = "âœ…" if result.intent == expected_intent else "âŒ"
        print(f"{status} '{text}' â†’ {result.intent.value} "
              f"(ç½®ä¿¡åº¦: {result.confidence:.2f})")
    
    print("\n" + "=" * 60)
